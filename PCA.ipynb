{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    l2ratio = np.sum((y_true - y_pred)**2) / np.sum(y_true**2)\n",
    "    return np.sqrt(l2ratio) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(fnames):\n",
    "    import h5py\n",
    "    try:\n",
    "        h5_file = h5py.File(fnames, 'r')\n",
    "        a_group_key = list(h5_file.keys())[0]\n",
    "        eeg_data = np.array(h5_file[a_group_key]).T\n",
    "    except FileNotFoundError:\n",
    "        eeg_data = None\n",
    "    return [eeg_data, eeg_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"/yakushin/eeg/data/train/\"\n",
    "train_names = [x for x in os.listdir(train_dir) \n",
    "                 if x[-3:] == \".h5\"]\n",
    "data = [x for x in load_file.map([train_dir + f for f in train_names]) if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([x[0] for x in data], axis = 0)\n",
    "X_train_size = np.cumsum(np.array([x[1] for x in data]))\n",
    "X_train_delete_channels = find_bad_channels(X_train, X_train_size)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_new_data():\n",
    "    eeg_dir = \"/yakushin/eeg/data/test/\"\n",
    "    eeg_names = [x for x in os.listdir(eeg_dir) \n",
    "                    if x[-3:] == \".h5\"]\n",
    "    data = np.concatenate([x for x in \n",
    "                                load_file.map([eeg_dir + f for f in eeg_names]) \n",
    "                                    if x is not None], axis=0)\n",
    "    return np.concatenate([x[0] for x in data], axis = 0), np.cumsum(np.array([x[1] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, X_test_size = load_new_data()\n",
    "X_test_delete_channels = find_bad_channels(X_test, X_test_size)\n",
    "X_test_delete_channels = []\n",
    "start = 0\n",
    "for finish in X_test_size:\n",
    "    part_data = X_test[start : finish]\n",
    "    X_train_delete_channels.append([])\n",
    "    for i in range(58):\n",
    "        part_data[:, i]\n",
    "        if (np.array_equal(part_data[:, i],np.zeros(finish - start))):\n",
    "            X_train_delete_channels[-1].append(i)\n",
    "    start = finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L2RatioTester(object):\n",
    "    def metric(self, y_true, y_pred):\n",
    "        l2ratio = np.sum((y_true - y_pred)**2) / np.sum(y_true**2)\n",
    "        return np.sqrt(l2ratio) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components_count = components_count = np.logspace(1, 58, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metric(n_components):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    return (tester.metric(X_test, pca.inverse_transform(pca.transform(X_test)))\n",
    "    , tester.metric(X_train, pca.inverse_transform(pca.transform(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lview['X_train'] = X_train[:200000]\n",
    "lview['X_test'] = X_test[:200000]\n",
    "lview['L2RatioTester'] = L2RatioTester\n",
    "lview['tester'] = L2RatioTester()\n",
    "l2_ratio = calc_metric.map(components_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
